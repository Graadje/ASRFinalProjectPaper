{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keZIC6a-OkZQ"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchaudio speechbrain torchattacks matplotlib numpy pystoi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBZUEVJUPCQr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from speechbrain.pretrained import EncoderClassifier\n",
        "import torchattacks\n",
        "\n",
        "#model gave an error when not using cpu, we used cpu mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Using\", device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_dev(t):\n",
        "    \"\"\"Move any tensor or list/tuple of tensors to the global device.\"\"\"\n",
        "    if isinstance(t, (list, tuple)):\n",
        "        return type(t)(to_dev(x) for x in t)\n",
        "    return t.to(device, non_blocking=True)"
      ],
      "metadata": {
        "id": "b-oe32rAVOhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQJM3LIdPejh"
      },
      "outputs": [],
      "source": [
        "#Token Huggingface ASR_TOKEN = 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 (Just copy and paste)\n",
        "!huggingface-cli login\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1sUzSbTSPKY"
      },
      "outputs": [],
      "source": [
        "from speechbrain.inference.classifiers import EncoderClassifier\n",
        "\n",
        "classifier = (\n",
        "    EncoderClassifier.from_hparams(\n",
        "        source=\"speechbrain/spkrec-xvect-voxceleb\",\n",
        "        savedir=\"pretrained_models/spkrec-xvect-voxceleb\",\n",
        "    )\n",
        "    .to(device)\n",
        "    .eval()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugid5skSSkQY"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"kryakrya/voxceleb1test\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvRPrlf_XRUt"
      },
      "outputs": [],
      "source": [
        "!cp -r /root/.cache/kagglehub/datasets/kryakrya/voxceleb1test/versions/1 /content/voxcelebtest-1-dataset\n",
        "import os\n",
        "print(os.listdir(\"/content/voxcelebtest-1-dataset\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mV25_MAzXaNS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torchaudio\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "# full file path\n",
        "file_path = \"/content/voxcelebtest-1-dataset/wav/id10270/5r0dWxy17C8/00001.wav\"\n",
        "\n",
        "# Check if the file exists\n",
        "if os.path.exists(file_path):\n",
        "    # Load the audio file\n",
        "    waveform, sample_rate = torchaudio.load(file_path)\n",
        "    print(f\"Loaded file: {file_path}\")\n",
        "    print(f\"Sample Rate: {sample_rate}, Waveform shape: {waveform.shape}\")\n",
        "\n",
        "    # If the waveform has extra dimensions, squeeze them\n",
        "    waveform_np = waveform.squeeze().cpu().numpy()\n",
        "\n",
        "    # Use the display function to ensure the Audio widget is rendered\n",
        "    display(Audio(waveform_np, rate=sample_rate))\n",
        "else:\n",
        "    print(\"The audio file was not found at the specified path.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zH1yVC43zUX1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "from IPython.display import Audio, display\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Load the audio file.\n",
        "# Adjust the file path to your specific testfile in your VoxCeleb test dataset.\n",
        "file_path = \"/content/voxcelebtest-1-dataset/wav/id10270/5r0dWxy17C8/00002.wav\"\n",
        "\n",
        "# Check if the file exists\n",
        "if not os.path.exists(file_path):\n",
        "    print(f\"File not found: {file_path}\")\n",
        "else:\n",
        "    waveform, sample_rate = torchaudio.load(file_path)\n",
        "    print(f\"Loaded file: {file_path}\")\n",
        "    print(f\"Original sample rate: {sample_rate}, Waveform shape: {waveform.shape}\")\n",
        "\n",
        "    #Resample to 16kHz if needed. We used 16kHz\n",
        "    target_sr = 16000\n",
        "    if sample_rate != target_sr:\n",
        "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=target_sr)\n",
        "        waveform = resampler(waveform)\n",
        "        sample_rate = target_sr\n",
        "    print(f\"Resampled to: {sample_rate}, Waveform shape: {waveform.shape}\")\n",
        "\n",
        "    # Step 2: Define a function that simulates an adversarial attack.\n",
        "    # Here we add a perturbation: epsilon * sign(random noise) Epsilon is our noise tweaking parameter\n",
        "    def fake_attack(audio, epsilon):\n",
        "        # Generate a random noise tensor with the same shape as the audio\n",
        "        random_noise = torch.randn_like(audio)\n",
        "        # Take the sign to simulate the direction of a gradient\n",
        "        perturbation = epsilon * random_noise.sign()\n",
        "        # Add the perturbation to the original audio\n",
        "        attacked_audio = audio + perturbation\n",
        "        # Ensure the audio values remain in the valid range [-1, 1]\n",
        "        attacked_audio = torch.clamp(attacked_audio, -1, 1)\n",
        "        return attacked_audio\n",
        "\n",
        "    # Step 3: Generate adversarial versions for different epsilon values.\n",
        "    epsilons = [0.0, 0.01, 0.05, 0.1, 0.2]\n",
        "    attacked_versions = {}\n",
        "    for eps in epsilons:\n",
        "        attacked_versions[eps] = fake_attack(waveform, eps)\n",
        "\n",
        "    # Step 4: Listen and compare the versions.\n",
        "    print(\"Playing audio samples with different epsilon values:\")\n",
        "    for eps, audio_tensor in attacked_versions.items():\n",
        "        print(f\"Epsilon = {eps}\")\n",
        "        # Convert tensor to numpy array and squeeze extra dimensions\n",
        "        audio_np = audio_tensor.squeeze().detach().cpu().numpy()\n",
        "        display(Audio(audio_np, rate=sample_rate))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syPdwT2-1DUl"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Wrap the SpeechBrain Classifier\n",
        "# The SpeechBrain classifier’s `classify_batch` method returns a tuple:\n",
        "# (output_probs, score, index, text_lab). We wrap it so that it returns only the output probabilities (logits),\n",
        "# which Torchattacks (and our FGSM code) require.\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class ClassifierWrapper(nn.Module):\n",
        "    def __init__(self, clf):\n",
        "        super().__init__()\n",
        "        self.clf = clf\n",
        "    def forward(self, audio):\n",
        "        logits, _, _, _ = self.clf.classify_batch(to_dev(audio))\n",
        "        return logits\n",
        "\n",
        "\n",
        "classifier = classifier.to(device)\n",
        "wrapped_model = ClassifierWrapper(classifier).to(device)\n",
        "\n",
        "print(\"Wrapped model ready for FGSM attack.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ9Z4ZFj1E1W"
      },
      "outputs": [],
      "source": [
        "#prediction function that generates predicted label for audio\n",
        "def get_prediction(audio):\n",
        "    assert audio.device == next(wrapped_model.parameters()).device\n",
        "    audio = to_dev(audio)\n",
        "    output = wrapped_model(audio)\n",
        "    return output.argmax(dim=1)\n",
        "\n",
        "waveform = to_dev(waveform)\n",
        "clean_pred = get_prediction(waveform)\n",
        "\n",
        "print(clean_pred)\n",
        "print(\"Baseline (clean) predicted label:\", clean_pred.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kSC0Nll1kua"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compute the FGSM Attack (White-Box Method)\n",
        "# We will now compute the gradient of the loss with respect to the audio input and generate an adversarial example.\n",
        "# First, we prepare a loss function and convert the clean predicted label to a target label tensor.\n",
        "# For a non-targeted attack, we use the model’s own prediction as the label.\n",
        "\n",
        "# Convert the clean prediction to a tensor of type Long.\n",
        "label_tensor = clean_pred.clone().detach().type(torch.long).to(device)\n",
        "\n",
        "# Ensure that waveform requires gradients so that we can compute gradients.\n",
        "waveform.requires_grad = True\n",
        "\n",
        "# Forward pass: Compute the output for the clean audio using the wrapped model.\n",
        "output = wrapped_model(waveform)\n",
        "\n",
        "# Compute the loss. Here we use negative log likelihood loss.\n",
        "loss = F.nll_loss(output, label_tensor)\n",
        "\n",
        "# Zero out any existing gradients.\n",
        "wrapped_model.zero_grad()\n",
        "\n",
        "# Backward pass: Compute gradients of the loss with respect to the waveform.\n",
        "loss.backward()\n",
        "\n",
        "# Retrieve the gradients from the waveform.\n",
        "data_grad = waveform.grad.data\n",
        "\n",
        "# Define the FGSM attack function.\n",
        "def fgsm_attack(audio, epsilon, data_grad):\n",
        "    # Create the perturbation: multiply epsilon by the sign of the gradient.\n",
        "    perturbed_audio = audio + epsilon * data_grad.sign()\n",
        "    # Clamp the perturbed audio to be within the valid range (-1, 1).\n",
        "    perturbed_audio = torch.clamp(perturbed_audio, -1, 1)\n",
        "    return perturbed_audio\n",
        "\n",
        "# Choose an epsilon value for the attack.\n",
        "epsilon = 0.00009\n",
        "\n",
        "# Generate the adversarial example.\n",
        "adv_waveform = fgsm_attack(waveform, epsilon, data_grad)\n",
        "print(\"Adversarial waveform generated.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pVTLL5R1oyI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Evaluate and Compare Predictions\n",
        "#\n",
        "# Now, let’s get the predictions from the model on both the clean and adversarial audio samples.\n",
        "\n",
        "clean_pred_after = get_prediction(waveform)\n",
        "adv_pred = get_prediction(adv_waveform)\n",
        "\n",
        "print(\"Clean predicted label:\", clean_pred_after.item())\n",
        "print(\"Adversarial predicted label (epsilon = {:.3f}):\".format(epsilon), adv_pred.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiAp9GrU1uNs"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Listen to the Clean vs. Adversarial Audio\n",
        "#\n",
        "# Finally, we can listen to both the original and the adversarial audio.\n",
        "# We'll convert the tensors to NumPy arrays and use IPython’s Audio widget to play them.\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "# Convert the audio to numpy for playback + squeeze.\n",
        "clean_audio_np = waveform.squeeze().detach().cpu().numpy()\n",
        "adv_audio_np = adv_waveform.squeeze().detach().cpu().numpy()\n",
        "\n",
        "print(\"Playing clean audio:\")\n",
        "display(Audio(clean_audio_np, rate=sample_rate))\n",
        "\n",
        "print(\"Playing adversarial audio (epsilon = {:.3f}):\".format(epsilon))\n",
        "display(Audio(adv_audio_np, rate=sample_rate))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCS-jPiLK0xE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.functional as F_audio\n",
        "import torch.nn.functional as F\n",
        "from IPython.display import Audio, display\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Next attacks, Black-Box methods\n",
        "# We will simulate noise injections\n",
        "\n",
        "\n",
        "# Get the baseline prediction for the clean audio\n",
        "clean_pred = get_prediction(waveform)\n",
        "print(\"Baseline (clean) predicted label:\", clean_pred)\n",
        "\n",
        "# 1. High-Frequency Noise Attack (Dev1 and Dev2 max hearing cutoff)\n",
        "def high_frequency_noise_attack_v2(audio, epsilon, cutoff=18000):\n",
        "    # Generate random noise with same shape as the input audio.\n",
        "    noise = torch.randn_like(audio)\n",
        "    # Apply a high-pass filter to the noise:\n",
        "\n",
        "    # The model expects the audio at sample_rate\n",
        "    filtered_noise = F_audio.highpass_biquad(noise, sample_rate, cutoff_freq=cutoff)\n",
        "    # Use the sign of the filtered noise scaled by epsilon\n",
        "    perturbation = epsilon * filtered_noise.sign()\n",
        "    attacked_audio = audio + perturbation\n",
        "    attacked_audio = torch.clamp(attacked_audio, -1, 1)\n",
        "    return attacked_audio\n",
        "\n",
        "# 2. Low-Epsilon Random Noise Attack (Like static white-noise)\n",
        "def low_epsilon_random_noise_attack(audio, epsilon):\n",
        "    noise = torch.randn_like(audio)\n",
        "    perturbation = epsilon * noise.sign()\n",
        "    attacked_audio = audio + perturbation\n",
        "    attacked_audio = torch.clamp(attacked_audio, -1, 1)\n",
        "    return attacked_audio\n",
        "\n",
        "# Define lists of epsilon values to test for both methods.\n",
        "epsilons_hf = [0.0, 0.001, 0.005, 0.01, 0.02]\n",
        "epsilons_low = [0.0, 0.0005, 0.001, 0.002, 0.005]\n",
        "\n",
        "# Dictionaries to store predictions for each method\n",
        "predictions_hf = {}\n",
        "predictions_low = {}\n",
        "\n",
        "#Testing attacks below:\n",
        "\n",
        "# High-Frequency Noise Attack: Loop over epsilons, add noise, and get prediction.\n",
        "print(\"High-Frequency Noise Attack with cutoff=10000 Hz:\")\n",
        "for eps in epsilons_hf:\n",
        "    adv_audio_hf = high_frequency_noise_attack_v2(waveform, eps, cutoff=18000)\n",
        "    pred_label = get_prediction(adv_audio_hf)\n",
        "    predictions_hf[eps] = pred_label\n",
        "    print(f\"  Epsilon: {eps} -> Predicted Label: {pred_label}\")\n",
        "\n",
        "# Low-Epsilon Random Noise Attack: Loop over epsilons, add noise, and get prediction.\n",
        "print(\"\\nLow-Epsilon Random Noise Attack:\")\n",
        "for eps in epsilons_low:\n",
        "    adv_audio_low = low_epsilon_random_noise_attack(waveform, eps)\n",
        "    pred_label = get_prediction(adv_audio_low)\n",
        "    predictions_low[eps] = pred_label\n",
        "    print(f\"  Epsilon: {eps} -> Predicted Label: {pred_label}\")\n",
        "\n",
        "# For listening, let's create a quick playback for one example from each technique.\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "# Choose a mid-value epsilon for each method to listen.\n",
        "test_eps_hf = epsilons_hf[2]  # e.g., 0.005 for HF noise\n",
        "test_eps_low = epsilons_low[2]  # e.g., 0.001 for low epsilon noise\n",
        "\n",
        "# Generate attacked audio\n",
        "adv_audio_hf = high_frequency_noise_attack_v2(waveform, test_eps_hf, cutoff=10000)\n",
        "adv_audio_low = low_epsilon_random_noise_attack(waveform, test_eps_low)\n",
        "\n",
        "# Convert to numpy for playback + squeeze\n",
        "clean_audio_np = waveform.squeeze().detach().cpu().numpy()\n",
        "adv_audio_hf_np = adv_audio_hf.squeeze().detach().cpu().numpy()\n",
        "adv_audio_low_np = adv_audio_low.squeeze().detach().cpu().numpy()\n",
        "\n",
        "print(\"\\nPlaying Clean Audio:\")\n",
        "display(Audio(clean_audio_np, rate=sample_rate))\n",
        "print(f\"Playing High-Frequency Noise Audio (epsilon = {test_eps_hf}):\")\n",
        "display(Audio(adv_audio_hf_np, rate=sample_rate))\n",
        "print(f\"Playing Low-Epsilon Random Noise Audio (epsilon = {test_eps_low}):\")\n",
        "display(Audio(adv_audio_low_np, rate=sample_rate))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xx4YuIoU29W6"
      },
      "outputs": [],
      "source": [
        "import torch, torchaudio, pandas as pd, numpy as np\n",
        "from pystoi import stoi                                # pip install pystoi\n",
        "\n",
        "#Define Objective metrics SNR and STOI, and a get label from classifier function\n",
        "\n",
        "def snr_db(clean, adv):\n",
        "    noise = adv - clean\n",
        "    return (10 * torch.log10(clean.pow(2).mean() / noise.pow(2).mean())\n",
        "              .item())\n",
        "\n",
        "def stoi_score(clean, adv, sr=16000):\n",
        "    return stoi(clean.squeeze().cpu().numpy(),\n",
        "                adv.squeeze().cpu().numpy(), sr)\n",
        "\n",
        "def get_label(wav):\n",
        "    return classifier.classify_batch(wav)[1].item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSmcmmUEqkPl"
      },
      "outputs": [],
      "source": [
        "#This code makes the list of Test_files we are going to use for the Subjective and Objective testing (Both Developers used the same Test_files list)\n",
        "\n",
        "\n",
        "import glob, os, random, itertools\n",
        "\n",
        "vox_root = \"/content/voxcelebtest-1-dataset/wav\"          # adjust if needed\n",
        "all_files = glob.glob(os.path.join(vox_root, \"**/*.wav\"), recursive=True)\n",
        "\n",
        "# 1) bucket by speaker\n",
        "by_spk = {}\n",
        "for p in all_files:\n",
        "    spk = os.path.basename(os.path.dirname(os.path.dirname(p)))   # id10270\n",
        "    by_spk.setdefault(spk, []).append(p)\n",
        "\n",
        "# 2) shuffle each speaker list\n",
        "for spk, lst in by_spk.items():\n",
        "    random.shuffle(lst)\n",
        "\n",
        "# 3) round–robin draw until we hit 200\n",
        "target_N = 200\n",
        "test_files = []\n",
        "# create an iterator that cycles through speakers endlessly\n",
        "cyclers = itertools.cycle(by_spk.items())\n",
        "\n",
        "while len(test_files) < target_N:\n",
        "    spk, lst = next(cyclers)\n",
        "    if lst:                         # still files left for this speaker\n",
        "        test_files.append(lst.pop())  # pop one file\n",
        "    else:\n",
        "        del by_spk[spk]             # speaker exhausted → remove from cycle\n",
        "        cyclers = itertools.cycle(by_spk.items())\n",
        "    if not by_spk:                  # ran out of speakers before hitting N\n",
        "        break\n",
        "\n",
        "print(len(test_files), \"files selected from\",\n",
        "      len({os.path.basename(os.path.dirname(os.path.dirname(f))) for f in test_files}),\n",
        "      \"different speakers\")\n",
        "print(test_files[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COib3v5P3VOr"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "#Make a function that evaluates the attack on certain epsilon levels. This function generates the dataframe with results\n",
        "def eval_attack(name, attack_fn, eps_list):\n",
        "    rows = []\n",
        "    for eps in tqdm(eps_list, desc=f\"{name} ε-loop\"):\n",
        "        acc_clean = acc_adv = fooled = 0\n",
        "        snr_vals, stoi_vals = [], []\n",
        "\n",
        "        # One tick per test file\n",
        "        for f in tqdm(test_files, leave=False, desc=f\"ε={eps:0.4g}\"):\n",
        "            wav, sr = torchaudio.load(f)\n",
        "            if sr != 16000:\n",
        "                wav = torchaudio.functional.resample(wav, sr, 16000)\n",
        "            wav = wav.to(device)\n",
        "\n",
        "            y_clean = get_label(wav)\n",
        "\n",
        "            y_clean = get_label(wav)\n",
        "\n",
        "            if eps == 0:\n",
        "                wav_adv = wav\n",
        "            else:\n",
        "                wav_adv = attack_fn(wav.clone(), eps)\n",
        "\n",
        "            y_adv = get_label(wav_adv)\n",
        "\n",
        "            if eps == 0 and y_clean != y_adv:\n",
        "                print(\"ε=0 mismatch:\", f, y_clean, y_adv)\n",
        "            # true-ID extraction\n",
        "            true_id = os.path.basename(os.path.dirname(os.path.dirname(f)))\n",
        "            print(y_clean, y_adv)\n",
        "            acc_clean += (y_clean == true_id)\n",
        "            acc_adv   += (y_adv   == true_id)\n",
        "            fooled    += (y_clean != y_adv)\n",
        "\n",
        "            #add to results lists\n",
        "            snr_vals.append(snr_db(wav, wav_adv))\n",
        "            stoi_vals.append(stoi_score(wav, wav_adv))\n",
        "\n",
        "        N = len(test_files)\n",
        "        rows.append(dict(Attack=name, eps=eps,\n",
        "                         SNR=np.mean(snr_vals),\n",
        "                         STOI=np.mean(stoi_vals),\n",
        "                         ASR = 100*fooled/N,\n",
        "                         Acc_clean = 100*acc_clean/N,\n",
        "                         Acc_adv   = 100*acc_adv/N,\n",
        "                         ΔAcc = 100*acc_clean/N - 100*acc_adv/N))\n",
        "    return pd.DataFrame(rows)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfW8QX1Du00v"
      },
      "outputs": [],
      "source": [
        "#Make a FGSM (White-Box attack) wrapper to use for the actual experiment\n",
        "class FGSM_Wrap:\n",
        "    def __init__(self, model):\n",
        "        self.m = model\n",
        "\n",
        "    def __call__(self, wav, eps):\n",
        "        if eps == 0:\n",
        "            return wav\n",
        "\n",
        "        with torch.enable_grad():\n",
        "            wav_r = wav.clone().detach().requires_grad_(True)\n",
        "            logits = self.m(wav_r)\n",
        "            target = logits.max(1)[1]\n",
        "            loss   = F.nll_loss(logits, target)\n",
        "\n",
        "            self.m.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            perturb = eps * wav_r.grad.sign()\n",
        "            adv = torch.clamp(wav + perturb, -1, 1).detach()\n",
        "        return adv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSWsOr1Wu5Mo"
      },
      "outputs": [],
      "source": [
        "fgsm_attack = FGSM_Wrap(wrapped_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfJjTYTW3Z7r"
      },
      "outputs": [],
      "source": [
        "#Used Epsilon values for Experiemnt for every attack method\n",
        "eps_random = [0, 0.0003, 0.0005, 0.001, 0.002, 0.005, 0.01]\n",
        "eps_high   = [0, 0.0005, 0.001, 0.003, 0.005, 0.01, 0.02]\n",
        "eps_fgsm   = [0, 0.0003, 0.0005, 0.001, 0.002, 0.003]\n",
        "\n",
        "df_fgsm   = eval_attack(\"FGSM\",       fgsm_attack,      eps_fgsm)\n",
        "\n",
        "df_random = eval_attack(\"Low‑ε Rand\", low_epsilon_random_noise_attack, eps_random)\n",
        "df_high   = eval_attack(\"High‑freq\",  high_frequency_noise_attack_v2,  eps_high)\n",
        "\n",
        "results = pd.concat([df_random, df_high, df_fgsm], ignore_index=True)\n",
        "results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43xubRVy3cyy"
      },
      "outputs": [],
      "source": [
        "#Objective results\n",
        "results.to_csv(\"metric_table_new.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FssfwPa4tEF"
      },
      "outputs": [],
      "source": [
        "import random, itertools, pandas as pd\n",
        "\n",
        "attacks = {\n",
        "    \"rand\" : low_epsilon_random_noise_attack,\n",
        "    \"hf\"   : lambda wav,eps: high_frequency_noise_attack_v2(wav,eps, cutoff=10000),\n",
        "    \"fgsm\" : fgsm_attack,\n",
        "}\n",
        "eps_grid = {\n",
        "    \"rand\": [0, 0.0003, 0.0005, 0.001, 0.002, 0.005, 0.01],\n",
        "    \"hf\"  : [0, 0.0005, 0.001, 0.003, 0.005, 0.01, 0.02],\n",
        "    \"fgsm\": [0, 0.0003, 0.0005, 0.001, 0.002, 0.003]\n",
        "}\n",
        "\n",
        "import pandas as pd, random\n",
        "\n",
        "\n",
        "trial_rows = []\n",
        "for wav in test_files:\n",
        "    for atk, grid in eps_grid.items():\n",
        "        for eps in grid:\n",
        "            if eps == 0:\n",
        "                # one clean copy per file\n",
        "                trial_rows.append(dict(wav=wav, attack=\"clean\", eps=0.0))\n",
        "            else:\n",
        "                trial_rows.append(dict(wav=wav, attack=atk, eps=eps))\n",
        "\n",
        "trial_master = pd.DataFrame(trial_rows)\n",
        "trial_master.to_csv(\"trial_master.csv\", index=False)\n",
        "print(\"Saved canonical list with\",\n",
        "      len(trial_master), \"rows to trial_master.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBnoxeKPfCT2"
      },
      "outputs": [],
      "source": [
        "#Make a subjective session function for the developers to do the experiment on the test-files for retrieving the MOS and ABX\n",
        "def subjective_session(trial_df, listener_id):\n",
        "    rows = []\n",
        "    for tidx, row in trial_df.iterrows():\n",
        "        wav_path, atk, eps = row.wav, row.attack, row.eps\n",
        "\n",
        "        wav_t, sr0 = torchaudio.load(wav_path)\n",
        "        if sr0 != 16000:\n",
        "            wav_t = torchaudio.functional.resample(wav_t, sr0, 16000)\n",
        "        wav_t = wav_t.to(device)\n",
        "\n",
        "        wav_adv = (wav_t if atk == \"clean\"\n",
        "                   else attacks[atk](wav_t, eps))\n",
        "\n",
        "        # ABX\n",
        "        A, B = wav_t, wav_adv\n",
        "        X_is_attack = random.choice([True, False])\n",
        "        X = wav_adv if X_is_attack else wav_t\n",
        "\n",
        "        print(f\"\\nTrial {tidx+1}/{len(trial_df)}  listener {listener_id}\")\n",
        "        for tag, clip in [(\"A\",A), (\"B\",B), (\"X\",X)]:\n",
        "            print(tag); display(Audio(clip.squeeze().cpu().numpy(), rate=16000))\n",
        "\n",
        "        mos = input(\"Rate B (1-5): \").strip()\n",
        "        while mos not in {'1','2','3','4','5'}:\n",
        "            mos = input(\"Please type 1-5: \").strip()\n",
        "\n",
        "        guess = input(\"Is X clean (c) or attack (a)? \").lower().strip()\n",
        "        while guess not in {'c','a'}:\n",
        "            guess = input(\"Type 'c' or 'a': \").lower().strip()\n",
        "\n",
        "        abx_correct = int((guess == 'a') == X_is_attack)\n",
        "\n",
        "        rows.append(dict(listener=listener_id,\n",
        "                         wav=wav_path, attack=atk, eps=eps,\n",
        "                         mos=int(mos), abx=abx_correct))\n",
        "    # save immediately\n",
        "    out_csv = f\"mos_abx_{listener_id}.csv\"\n",
        "    pd.DataFrame(rows).to_csv(out_csv, index=False)\n",
        "    print(f\"\\nSaved subjective answers to {out_csv}\")\n",
        "    return pd.DataFrame(rows)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4Yr_32d43Ca"
      },
      "outputs": [],
      "source": [
        "#Load the trials for the developer tester\n",
        "def load_trials_for_listener(seed, max_utts=None):\n",
        "    df = pd.read_csv(\"trial_master.csv\")\n",
        "    df = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
        "    if max_utts:\n",
        "        keep = df['wav'].unique()[:max_utts]\n",
        "        df = df[df['wav'].isin(keep)].reset_index(drop=True)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUDVEBu1gG69"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#Save and Load Test_files list\n",
        "\n",
        "#Save\n",
        "pd.DataFrame(test_files, columns=[\"wav\"]).to_csv(\"test_files.csv\", index=False)\n",
        "print(\"Saved\", len(test_files), \"paths to test_files.csv\")\n",
        "\n",
        "#Load\n",
        "test_files = pd.read_csv(\"test_files.csv\")[\"wav\"].tolist()\n",
        "print(\"Reloaded\", len(test_files), \"paths\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2ux9RE16IOy"
      },
      "outputs": [],
      "source": [
        "#Run this cell to perform the Experiment for \"Dev1\"\n",
        "listener_id = \"dev1\"\n",
        "#IMPORTANT: Keep the same seed for all Devs\n",
        "trial_df = load_trials_for_listener(seed=1234, max_utts=10)\n",
        "df_dev1 = subjective_session(trial_df, listener_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPDtwJ55fsbU"
      },
      "outputs": [],
      "source": [
        "#Run this cell to perform the Experiment for \"Dev2\"\n",
        "listener_id = \"dev2\"\n",
        "#IMPORTANT: Keep the same seed as previous dev\n",
        "trial_df = load_trials_for_listener(seed=1234, max_utts=10)\n",
        "df_dev2 = subjective_session(trial_df, listener_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 1) load the listener’s CSV\n",
        "df = pd.read_csv(\"mos_abx_dev2.csv\")\n",
        "\n",
        "# 2) compute per-attack / ε averages\n",
        "summary = (df\n",
        "           .groupby(['attack', 'eps'])\n",
        "           .agg(MOS=('mos',  'mean'),\n",
        "                ABX_perc=('abx', 'mean'))     # fraction correct\n",
        "           .reset_index())\n",
        "\n",
        "summary['ABX_perc'] *= 100                    # turn into %\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "Z3Gapkrzvh4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Ensure eps is numeric and sorted for better plotting\n",
        "summary['eps'] = summary['eps'].astype(float)\n",
        "summary = summary.sort_values(by='eps')\n",
        "\n",
        "#Plot 1: MOS vs ε\n",
        "plt.figure(figsize=(7, 4))\n",
        "for atk, grp in summary.groupby('attack'):\n",
        "    plt.plot(grp['eps'], grp['MOS'], marker='o', label=atk)\n",
        "plt.xlabel(\"ε (epsilon)\")\n",
        "plt.ylabel(\"Mean Opinion Score (MOS)\")\n",
        "plt.title(\"MOS vs ε for each attack type\")\n",
        "plt.grid(True, linestyle='--', linewidth=0.5)\n",
        "plt.legend(title=\"Attack\")\n",
        "plt.xscale('log')                # ε values span orders of magnitude\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#Plot 2: ABX% vs ε\n",
        "plt.figure(figsize=(7, 4))\n",
        "for atk, grp in summary.groupby('attack'):\n",
        "    plt.plot(grp['eps'], grp['ABX_perc'], marker='o', label=atk)\n",
        "plt.xlabel(\"ε (epsilon)\")\n",
        "plt.ylabel(\"ABX correct (%)\")\n",
        "plt.title(\"ABX accuracy vs ε for each attack type\")\n",
        "plt.grid(True, linestyle='--', linewidth=0.5)\n",
        "plt.legend(title=\"Attack\")\n",
        "plt.xscale('log')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OcqhD1dnwJVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Get Combined Results (of both testers) in plot\n",
        "\n",
        "# Load both CSVs\n",
        "df1 = pd.read_csv(\"mos_abx_dev1.csv\")\n",
        "df2 = pd.read_csv(\"mos_abx_dev2.csv\")\n",
        "\n",
        "# Add source labels\n",
        "df1['listener'] = 'Dev1'\n",
        "df2['listener'] = 'Dev2'\n",
        "\n",
        "# Combine\n",
        "df_all = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# Compute per-listener / attack / epsilon means\n",
        "summary = (df_all\n",
        "           .groupby(['listener', 'attack', 'eps'])\n",
        "           .agg(MOS=('mos', 'mean'),\n",
        "                ABX_perc=('abx', 'mean'))\n",
        "           .reset_index())\n",
        "summary['ABX_perc'] *= 100\n",
        "\n",
        "#Plot 1: MOS\n",
        "plt.figure(figsize=(7, 4))\n",
        "for (atk, lst), grp in summary.groupby(['attack', 'listener']):\n",
        "    label = f\"MOS{lst} - {atk}\" if atk != 'clean' else None\n",
        "    plt.plot(grp['eps'], grp['MOS'], marker='o', label=label)\n",
        "plt.xlabel(\"ε (epsilon)\")\n",
        "plt.ylabel(\"Mean Opinion Score (MOS)\")\n",
        "plt.title(\"MOS vs ε per listener and attack\")\n",
        "plt.grid(True, linestyle='--', linewidth=0.5)\n",
        "plt.legend()\n",
        "plt.xscale('log')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#Plot 2: ABX%\n",
        "plt.figure(figsize=(7, 4))\n",
        "for (atk, lst), grp in summary.groupby(['attack', 'listener']):\n",
        "    label = f\"ABX{lst} - {atk}\" if atk != 'Clean' else None\n",
        "    plt.plot(grp['eps'], grp['ABX_perc'], marker='o', label=label)\n",
        "plt.xlabel(\"ε (epsilon)\")\n",
        "plt.ylabel(\"ABX correct (%)\")\n",
        "plt.title(\"ABX accuracy vs ε per listener and attack\")\n",
        "plt.grid(True, linestyle='--', linewidth=0.5)\n",
        "plt.legend()\n",
        "plt.xscale('log')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zxqMrYKChpzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now an average combined plot version\n",
        "df1 = pd.read_csv(\"mos_abx_dev1.csv\")\n",
        "df2 = pd.read_csv(\"mos_abx_dev2.csv\")\n",
        "df_all = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# Group across all listeners to get averaged values\n",
        "avg_summary = (df_all\n",
        "               .groupby(['attack', 'eps'])\n",
        "               .agg(MOS=('mos', 'mean'),\n",
        "                    ABX_perc=('abx', 'mean'))\n",
        "               .reset_index())\n",
        "avg_summary['ABX_perc'] *= 100\n",
        "\n",
        "#Plot 1: Avg MOS\n",
        "plt.figure(figsize=(7, 4))\n",
        "for atk, grp in avg_summary.groupby('attack'):\n",
        "    label = None if atk == 'clean' else atk\n",
        "    plt.plot(grp['eps'], grp['MOS'], marker='o', label=label)\n",
        "plt.xlabel(\"ε (epsilon)\")\n",
        "plt.ylabel(\"Mean Opinion Score (MOS)\")\n",
        "plt.title(\"Average MOS vs ε (across listeners)\")\n",
        "plt.grid(True, linestyle='--', linewidth=0.5)\n",
        "plt.legend(title=\"Attack\")\n",
        "plt.xscale('log')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#Plot 2: Avg ABX%\n",
        "plt.figure(figsize=(7, 4))\n",
        "for atk, grp in avg_summary.groupby('attack'):\n",
        "    label = None if atk == 'clean' else atk\n",
        "    plt.plot(grp['eps'], grp['ABX_perc'], marker='o', label=label)\n",
        "plt.xlabel(\"ε (epsilon)\")\n",
        "plt.ylabel(\"ABX correct (%)\")\n",
        "plt.title(\"Average ABX accuracy vs ε (across listeners)\")\n",
        "plt.grid(True, linestyle='--', linewidth=0.5)\n",
        "plt.legend(title=\"Attack\")\n",
        "plt.xscale('log')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wTCefkVHieRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#Plots for objective metrics resutls\n",
        "# Load the objective metrics file\n",
        "obj = pd.read_csv(\"/content/metric_table_new.csv\").rename(columns={\"Attack\": \"attack\"})\n",
        "\n",
        "# Ensure eps is numeric for log plotting\n",
        "obj[\"eps\"] = obj[\"eps\"].astype(float)\n",
        "\n",
        "# Define a nice color palette\n",
        "palette = {\"Low‑ε Rand\": \"tab:blue\", \"High‑freq\": \"tab:green\", \"FGSM\": \"tab:red\"}\n",
        "\n",
        "#Plot 1: ASR vs ε\n",
        "plt.figure(figsize=(7, 4))\n",
        "for atk, grp in obj.groupby(\"attack\"):\n",
        "    plt.plot(grp[\"eps\"], grp[\"ASR\"], marker=\"o\", label=atk, color=palette.get(atk))\n",
        "plt.xscale(\"log\")\n",
        "plt.xlabel(\"ε (log scale)\")\n",
        "plt.ylabel(\"Attack‑success rate (ASR %)\")\n",
        "plt.title(\"ASR vs ε for each attack\")\n",
        "plt.grid(True, linestyle=\"--\", linewidth=0.4)\n",
        "plt.legend(title=\"Attack\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#Plot 2: STOI vs ε\n",
        "plt.figure(figsize=(7, 4))\n",
        "for atk, grp in obj.groupby(\"attack\"):\n",
        "    plt.plot(grp[\"eps\"], grp[\"STOI\"], marker=\"o\", label=atk, color=palette.get(atk))\n",
        "plt.xscale(\"log\")\n",
        "plt.xlabel(\"ε (log scale)\")\n",
        "plt.ylabel(\"STOI (0‑1)\")\n",
        "plt.title(\"STOI vs ε for each attack\")\n",
        "plt.grid(True, linestyle=\"--\", linewidth=0.4)\n",
        "plt.legend(title=\"Attack\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#Plot 3: SNR vs ε\n",
        "plt.figure(figsize=(7, 4))\n",
        "for atk, grp in obj.groupby(\"attack\"):\n",
        "    plt.plot(grp[\"eps\"], grp[\"SNR\"], marker=\"o\", label=atk, color=palette.get(atk))\n",
        "plt.xscale(\"log\")\n",
        "plt.xlabel(\"ε (log scale)\")\n",
        "plt.ylabel(\"SNR (dB)\")\n",
        "plt.title(\"SNR vs ε for each attack\")\n",
        "plt.grid(True, linestyle=\"--\", linewidth=0.4)\n",
        "plt.legend(title=\"Attack\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5YKFMbbIxaV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, pandas as pd, torchaudio\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "#Later made a second improved subjective session function where the intermediate results are saved so the dev doesn't have to test in one go\n",
        "def subjective_session_v2(trial_df, listener_id, csv_dir=\".\", sr_target=16000):\n",
        "    csv_path = os.path.join(csv_dir, f\"mos_abx_{listener_id}.csv\")\n",
        "\n",
        "\n",
        "    #Figure out which trials are already done\n",
        "\n",
        "    if os.path.exists(csv_path):\n",
        "        done = pd.read_csv(csv_path)\n",
        "        done_keys = set(zip(done.wav, done.attack, done.eps))\n",
        "        print(f\"Resuming: {len(done)} trials already saved for {listener_id}.\")\n",
        "    else:\n",
        "        done_keys = set()\n",
        "        print(f\"Starting fresh session for {listener_id}.\")\n",
        "\n",
        "\n",
        "    # Iterate through trials, skipping completed ones\n",
        "\n",
        "    for idx, row in trial_df.iterrows():\n",
        "        key = (row.wav, row.attack, row.eps)\n",
        "        if key in done_keys:\n",
        "            continue                      # already done\n",
        "\n",
        "        wav_path, atk, eps = key\n",
        "        wav_t, sr0 = torchaudio.load(wav_path)\n",
        "        if sr0 != sr_target:\n",
        "            wav_t = torchaudio.functional.resample(wav_t, sr0, sr_target)\n",
        "        wav_t = wav_t.to(device)\n",
        "\n",
        "        wav_adv = wav_t if atk == \"clean\" else attacks[atk](wav_t, eps)\n",
        "\n",
        "        # deterministic ABX shuffle (same for every restart)\n",
        "        rnd = random.Random(hash(key))\n",
        "        X_is_attack = rnd.choice([True, False])\n",
        "        A, B = wav_t, wav_adv\n",
        "        X = wav_adv if X_is_attack else wav_t\n",
        "\n",
        "        #playback & questions\n",
        "        total_trials = len(trial_df) - len(done_keys)\n",
        "        print(f\"\\nTrial {len(done_keys)+1}/{total_trials}  listener {listener_id}\")\n",
        "        for tag, clip in [(\"A\", A), (\"B\", B), (\"X\", X)]:\n",
        "            print(tag); display(Audio(clip.squeeze().cpu().numpy(), rate=sr_target))\n",
        "\n",
        "        mos = input(\"Rate B (1-5): \").strip()\n",
        "        while mos not in {'1','2','3','4','5'}:\n",
        "            mos = input(\"Please type 1-5: \").strip()\n",
        "\n",
        "        guess = input(\"Is X like clean (c) or attack (a)? \").lower().strip()\n",
        "        while guess not in {'c','a'}:\n",
        "            guess = input(\"Type 'c' or 'a': \").lower().strip()\n",
        "\n",
        "        abx_correct = int((guess == 'a') == X_is_attack)\n",
        "\n",
        "        #append row immediately\n",
        "        row_dict = dict(listener=listener_id, wav=wav_path,\n",
        "                        attack=atk, eps=eps,\n",
        "                        mos=int(mos), abx=abx_correct)\n",
        "        header_needed = not os.path.exists(csv_path)\n",
        "        pd.DataFrame([row_dict]).to_csv(csv_path,\n",
        "                                        mode='a', header=header_needed,\n",
        "                                        index=False)\n",
        "\n",
        "        done_keys.add(key)                 # mark as completed\n",
        "        print(f\"Saved to {csv_path}  •  remaining {total_trials-len(done_keys)}\")\n",
        "\n",
        "    print(f\"\\n✅  All trials for {listener_id} are now complete.\")\n"
      ],
      "metadata": {
        "id": "RVrjxEqI1gfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run this cell to perform the subjective V2 session Experiment for \"Dev3\"\n",
        "listener_id = \"dev3\"\n",
        "#IMPORTANT: Keep the same seed as previous dev\n",
        "trial_df = load_trials_for_listener(seed=1234, max_utts=10)\n",
        "df_dev2 = subjective_session_v2(trial_df, listener_id)"
      ],
      "metadata": {
        "id": "u6RYbZOy1tbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0wGj0HifxDF"
      },
      "outputs": [],
      "source": [
        "# objective_df = (pd.read_csv(\"metric_table_new.csv\")\n",
        "#                   .rename(columns={\"Attack\": \"attack\"}))\n",
        "\n",
        "# # combine listeners\n",
        "# subj_df = (pd.concat([df_dev1, df_dev2])\n",
        "#              .groupby(['attack','eps'])\n",
        "#              .agg(MOS=('mos','mean'),\n",
        "#                   ABX_perc=('abx','mean'))\n",
        "#              .reset_index())\n",
        "# subj_df['ABX_perc'] *= 100\n",
        "\n",
        "# full = objective_df.merge(subj_df, on=['attack','eps'], how='left')\n",
        "# full.to_csv(\"full_metrics.csv\", index=False)\n",
        "# print(\"Full table saved to full_metrics.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}